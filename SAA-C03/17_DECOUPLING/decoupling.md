# sqs

핵심 키워드는 대기열 입니다. 

표준 대기열용 amazon sqs는 가장 오래된 서비스로 완전 관리형 서비스로 애플리케이션을 *분리하는 데 사용됩니다*

무제한 처리량을 얻을 수 있습니다. 처리량에 제한 이 없고 대기열에 있는 메시지 수에도 제한이 없습니다. 각 메시지는 수명이 짧습니다. 

sqs는 대기열 서비스이므로 높은 처리량, 높은 볼륨 등이 있어서 중복 메시지가 있을 수 있습니다. 

생산자는 간단하며 소비자는 일부 코드로 작성해야 하는 애플리케이션이고 aws 가상 서버에서 실행될 수 있습니다. lambda 함수 및 온프레미스 서버에서 실행 가능합니다. 

소비자들은 동시에 가질 수 있습니다. asg와 더불어 sqs를 사용하는것은 완벽한 사례입니다.

sqs 대기열에서 쓸 수있는 cloudwatch 지표는 대기열의 길이 입니다. 

*또한 프론트엔드의 경우 최적의 유형의 EC2 인스턴스 또는 아키텍처를
프론트엔드에 사용할 수 있습니다 백엔드의 경우
비디오 처리를 수행할 때 그래픽 처리 장치인 GPU가 있는 일부
EC2 인스턴스를 사용할 수 있습니다
이러한 유형의 인스턴스가
워크로드를 수행하는 데에 최적이기 때문입니다*

액세스 제어를 위해 IAM 정책은
SQS API에 대한 액세스를 규제할 수 있고
S3 버킷 정책과 유사한
SQS 액세스 정책도 있습니다

# sqs 메시지 가시성 시간 초과 

기본값으로는 메시지 가시성 시간 초과는 30 초입니다. *시간 초과 기간 내에 또 다른 요청이 들어와도 메시지가 반환 되지 않습니다. 즉 가시성 시간 초과 기간 내에서는 그 메시지는 다른 소비자들에게 보이지 않습니다.* 

*가시성 시간 초과가 경과되고 메시지가 삭제되지 않았다면 메시지는 대기열에 다시 넣습니다. 그럼 다른 소비자는 이전의 메시지를 받게 되고 중복 처리할 수 있는겁니다*


# sqs long polling

*sqs 대기열에 대한 api 호출 수를 최적화하고 지연시간을 줄이는 방법은 롱폴링입니다. 
롱폴링은 대기열에 아무것도 없다면 메시지 도착을 기다립니다.* 

# sqs fifo queue

이 SQS 대기열의 처리량에는 제한이 있습니다
묶음이 아닐 경우에는 초당 300개의 메시지를 처리하고
메시지를 묶음으로 보낸다면
그 처리량은 초당 3,000개가 됩니다
FIFO 대기열을 사용해서 순서를 확실히 할 수 있죠

# sqs with asg

asg 그룹을 자동으로 대기열 크기에 따라 확장시키기 위함으로 cloudwatch 지표인 대기열 길이를 보고 결정 가능합니다. 

*시나리오 중에 해당 고객 트랜잭션은 유실되고 이는 특정 트랜잭션에 오류가 발생한다면 쓰기 대상 db에서 sqs를 버퍼로 사용 가능합니다. db와 frontend 애플리케이션이 있다면 db에 바로 쓰는 대신 애플리케이션이 요청, 즉 트랜잭션을 일명 무한히 확장 가능 sqs 대기열에 먼저 쓰는 방법이 있습니다. 이렇게 하면 처리량 문제가 발생하지 않습니다. 여기서 asg 그룹으로 메시지를 대기열에서 제외 가능합니다.*

*지금 이 오토 스케일링 그룹의 유일한 목적은 메시지를 수신해서
데이터베이스로 삽입하는 작업이죠
메시지가 데이터베이스에 삽입되고 나면
기존 SQS 대기열에서 해당 메시지를 삭제합니다
이렇게 SQS를 버퍼로 사용하여
모든 트랜잭션이 데이터베이스에 쓰이도록 확인할 수 있습니다*

*이 패턴은 클라이언트에게 따로 데이터베이스에
쓰였다는 확인을 전송할 필요가 없을 때만 사용 가능합니다
하지만 SQS 대기열에 쓰기 작업이 일어났다는 것만으로도
결국 데이터베이스에 요청이 쓰일 테니 일종의 확인을 한 셈이죠
이는 데이터베이스 쓰기 간 분리와 애플리케이션 티어 간 분리에 활용되는데
애플리케이션이 요청을 전달받고
처리한 후 응답을 재전송하는 대신
이 과정을 분리하여 모든 요청을
프론트엔드 웹 애플리케이션에서 받고 해당 요청을 SQS 대기열로 전송하여
백엔드 처리 작업이 메시지를 전달받은 다음
준비되면 메시지를 처리하고 필요에 따라 스케일링하는 거죠*

*분리나 급격히 증가한 로드 혹은 시간초과 등의 문제에서
신속한 스케일링이 필요한 경우에는
SQS 대기열을 기억하시기 바랍니다*

# sns

pub/sub 즉 게시/구독이라는 것을 사용가능하며 메시지를 주제로 게시합니다. 

amazon sns 에서 이벤트 생산자는 하나의 sns 주제에만 메시지를 보냅니다. 주제별로 최대 1200만 이상의 구독자 까지 가능하며 계정당 가질 수 있는 주제 수는 최대 10만 개 입니다. 

구독제에게 게시 가능한것은 직접 이메일을 보내며 모바일 알림을 보낼 수 있습니다. 

또한 지정된 http 또는 https 엔드 포인트로 직접 데이터를 보낼 수 있습니다. 

Lambda에 보내거나 firehose를 통해 데이터를 s3나 redshift로 보낼 수 있습니다. 

알림이 발생하면 cloudwatch 경보 asg s3 버킷, lambda, rds 이벤트 등에 알림을 전송 가능합니다.

혹은 모마일 앱 sdk 전용 직접 게시 방벙 ㅣ있습니다. 플랫폼 애플리케이션을 만든 다음 엔드포인트를 만들고 게시하면 됩니다. 

보안 측면에서는 기본적으로 전송 중 암호화와 kms 키를 사용한 저장 데이터 암호화가 있습니다. 암호화 및 암호 해독은 클라이언트 몱입니다. 

엑세스 제어는 iam 정책 중십입니다. 모든 sns api가 aim 정책으로 규제되기 때문입니다. 
*s3 버킷 정책과 매우 유사한 sns 액세스 정책을 정의 가능합니다. sns 주제에 교차 계정 액세스 권한을 갖거나 s3 이벤트와 같은 서비스가 sns 주제에 작성할 수있도록 허용하려는 경우 매우 유용합니다*

# sns + sqs = fan out

sqs 대기열의 개별적 전송으로 문제가 발생가능하며 fan out 패턴을 사용해야 합니다. 예를 들어 두개의 대기열로 메시지를 전송하고 싶은 상황속에서 sns 한개의 메시지를 전송하고 대기열 두개가 sns 토픽을 구독하고 있을 경우 fraud detector 서비스와 배송 서비스가 각각 자신의 sqs 대기열에서 메시지를 읽을 수 있습니다. 

sqs 로 데이터 지속성, 지연처리 ,작업 재시도 등의 효과를 얻습니다. 이것은 대기열 접근 정책을 활용한 경우입니다. 

다음으로 교차 리전 배송은 한 리전의 sns 토픽이 다른 리전의 .sqs 대기열에 미시지를 보내는것입니다. 보안이 허용한다는 가정하에 입니다. 

첫번째 아키텍처는 여러개의 대기열이 sns 토픽에 fan out 패턴으로 구독하게 됩니다. 이것을 이용하여 이메일이나 lambda 함수 등 다른 형식의 애플리케이션도 sns 토픽을 구독하여 s3에서 일어나는 이벤트에 대한 메시지를 다른 목적지로 안전하게 전송합니다.

두번째 아키텍처는 kdf(kinesis data firehouse) 를 통해 sns 에서 s3로 직접 데이터를 보낼 수 있습니다. sns 가 kdf와 직접적을 통합되어 있기에 kdf 에서 s3버킷으로 보낼 수 있고 지원되는 kdf 특정 목적지 어디든 가능합니다.

sqs fifo를 사용하는 이유는 fandout을 할 때는 fan out, 정렬, 중복 제거가 필요하기 때문입니다. 

*메시지 필터링이란 sns 토픽 구독자들에게 전송할 메시지를 필터링하는 json 정책입니다.* 

*topic details*

# kinesis

실시간 스트리밍 데이터를 손쉽게 수집하고 처리하여 분석 가능합니다. 

1. kinesis data streams

여러개의 샤드로 구성되어 있습니다.1~n 번까지의 번호는 사전에 프로비저닝 해야합니다. 

데이터는 모든 샤드에 분배됩니다. 샤드는 데이터 수집률이나 소비율 측면에서 스트림의 용량을 결정합니다. 

모든 생산자는 매우 낮은 수준에서 sdk에 의존하며 kds 에 레코드를 전달합니다. 초당 1mb를 전송하고나 샤드당 1초에 천 개의 메시지를 전송합니다. 

소비자의 입장에서는 sdk에 의존하거나 높은 수준에서는 kinesis client library, kcl에 의존하는 애플리케이션이 있습니다. 

kinisis 스트림에서 서버리스로 처리하려는 경우 lambda 함수도 가능합니다. 

소비자마다 샤드당 초당 2mb 씩 받을 수있습니다. 데이터를 다시 처리하거나 확인할 수 있으며 kinesis 로 들어오면 삭제 불가능한 불변성이 있습니다. 

- 두가지 용량 유형

  - 프로비저닝 유형 : 프로비저닝할 샤드 슈를 정하고 api를 활용하거나 수동으로 조정합니다. 초당 1mb나 1천개의 레코드를 받아들입니다. 시간당 비용이 부과됩니다.
    
  - 온드맨드 : 프로비저닝 하거나 용량을 관리할 필요가 없습니다. 초당 4mb 또는 4천개의 레코드를 출력하며 비용은 시간당 스트림당 송수신 데이터양에 따라 비용이 부과됩니다.
 
- 보안 측면
  iam 정책을 사용해야 샤드를 생성하거 읽어 들이는 접근 권한을 제어합니다. https 로 전송 중 데이터를 암호화 하며 미사용 데이터는 cms로 암호화 가능합니다. 클라이언트 측에서 데이터를 암호화하거나 해독가능합니다. 이를 클라이언트 측 암호화 라고 합니다.

  vpc 엔드포인트를 사용 가능합니다. kinesis에 인터넷을 거치지 않고 프라이빗 서브넷의 인스턴스에서 직접 손쉡게 접근 가능합니다.

  api 요청을 cloudtrail로 감시 가능합니다.

  2. kinesis data firehose
 
     producers로부터 데이터를 가져올 수 있는 아주 유용한 서비스입니다. cloudwatch도 가능합니다. kdf 는 소스로부터 데이터를 가져옵니다. 가장 흔한 kds로부터입니다. 데이터를 여러 대상에 쓰는데 여러분은 어떤 코드도 쓸 필요 없습니다.

     대상에는 세종류가 있습니다.

     *첫번째 카테고리는 aws 대상인데 외워야 합니다.*
     첫번째는 s3이고 s3로 모든 데이터를 쓸 수 있습니다.
     두번째는 redshift로 웨어하우징 db입니다.
     세번째는 opensearch 입니다 서드 파티 파트너 대상도 잇습니다.  즉 데이터를 보낼 수 있는 파트너가 있다는것을 기억하면 됩니다.

     여러분이 http 엔드포인트를 갖는 자신의 api가 있다면 kdf에서 커스텀 대상으로 데이터를 보낼 수 있습니다. kdf는 완전관리형 서비스로 administration이 없고 자동 확장과 서버리스 기능을 가지기에 관리해야할 서버가 없습니다.
     Splunk, MongoDB, Datadog, New Relic 등등 서드 파티 파트너와

     그리고 근 실시간입니다. firehose로부터 대상으로 데이터를 묶어서 쓰기 때문에 60초의 지연이 생기며 최소 1mb 데이터가 쌓일 대까지 기다려야 합니다.


     *중요*

     Kinesis Data Streams는 대규모 데이터 수집을 위한 스트리밍 서비스로
producers와 consumers를 위해 커스텀 코드를 써야 합니다
200 밀리초나 70 밀리초로 실시간이고
직접 scaling을 관리해야 합니다

Shard splitting과 shard merging으로 규모와 처리량을 늘립니다
그리고 프로비저닝한 용량만큼 비용을 지불해야 합니다

Kinesis Data Stream의 데이터 저장은 1부터 365일까지 가능하고
이는 다양한 고객들이 같은 스트림으로부터 읽을 수 있게 합니다

그리고 또한 replay capability를 지원합니다

-- 

Kinesis Data Firehose는 데이터 수집 서비스로
S3, Redshift, OpenSearch, 서드 파티, 혹은 커스텀 HTTP로 데이터를 스트림할 수 있습니다

완전관리형이기에 관리할 서버가 없고
Near real-time(실시간에 가까움) 입니다
Near real-time(실시간에 가까움)은 시험 문제에서 자세히 봐야 할 키워드입니다

Automatic scaling 기능이 있고
Kinesis Data Firehose를 지나가는 데이터에 대해서만 비용을 지불하면 됩니다
데이터 저장이 없기 때문에 Kinesis Data Firehose로부터 데이터를 replay할 수 없습니다
Replay capability를 지원하지 않는다는 뜻입니다

# Ordering data into Kinesis

kinesis : 동일한 파티션 키를 사용했을 경우 같은 샤드에 저장됩니다. 

sqs : fifo 방식이며 그룹 id를 사용해여 fifo 내부에 그룹을 생성합니다. 그룹 id 가 많을 수록 소비자도 많아진다는 점입니다. 

즉, 그룹 id 숫자에 따른 동적 소비자 수를 원할대 사용하면 좋습니다. 

kinesis 데이트 스트림을 사용할경우 많은 데이터를 전송하거나 샤드당 데이터를 정렬할 때 사용합니다. 

# sqs, sns ,kinesis 차이점 *중요*





